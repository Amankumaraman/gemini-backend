# Gemini Backend Clone â€“ Kuvaka Tech

A scalable, production-ready backend system that replicates Gemini-style functionality: OTP-based authentication, chatroom management, asynchronous AI response via Redis queue, and Stripe-powered subscriptions.

Live Deployment: [https://gemini-backend-bjhb.onrender.com](https://gemini-backend-bjhb.onrender.com)
Postman Collection: *\[https://lunar-resonance-556494.postman.co/workspace/Demo~0a778c18-57ff-4c69-92c5-dfa9f196ef0b/collection/23158238-a9d823d7-5997-473b-bf1d-71c6c7c37f43?action=share&creator=23158238&active-environment=23158238-58645550-6c96-439d-8deb-29dce5d21aac]*

---

## ğŸš€ Tech Stack

* **Framework:** FastAPI
* **Database:** PostgreSQL
* **Queue:** Redis Queue (custom)
* **Cache:** Redis
* **Payments:** Stripe (Sandbox)
* **AI API:** Groq (OpenAI-compatible)
* **Auth:** OTP + JWT

---

## âœ… Features Implemented

### ğŸ” User Authentication

* OTP-based login (mocked, returned via response)
* JWT-based session management
* Password reset with OTP

### ğŸ’¬ Chatroom Management

* Authenticated users can:

  * Create multiple chatrooms
  * Send messages per chatroom
  * Receive Gemini (Groq API) responses asynchronously

### âš™ï¸ AI Integration (Gemini via Groq)

* Prompt sent to `Groq` via Redis queue worker
* AI responses saved in DB and retrievable
* Uses OpenAI-compatible Groq API (`llama3-70b-8192`)

### ğŸ” Async Queue with Redis

* Custom `push_task()` and `pop_task()` logic
* Redis-backed worker (`redis_worker.py`)
* Runs independently as a background process (deployed as Render Worker/Railway Worker)

### ğŸ’¸ Subscriptions via Stripe

* Checkout integration using Stripe sandbox
* Webhook on `/webhook/stripe` to upgrade user tier
* `/subscription/status` to check current plan
* Plans:

  * **Basic (Free)** â€“ 5 messages/day
  * **Pro (Paid)** â€“ Unlimited

### ğŸš¦ Rate Limiting

* Implemented via message counter for **Basic** users
* Restricts to 5 prompts/day per user (configurable via env)

### ğŸ§  Redis Caching

* Chatroom list cached per user (`GET /chatroom`)
* Improves dashboard loading
* TTL: 10 minutes

---

## ğŸ“ API Endpoints

| Endpoint                  | Method | Auth | Description                          |
| ------------------------- | ------ | ---- | ------------------------------------ |
| `/auth/signup`            | POST   | âŒ    | Register user (mobile only)          |
| `/auth/send-otp`          | POST   | âŒ    | Generate & send OTP (in response)    |
| `/auth/verify-otp`        | POST   | âŒ    | Verify OTP and receive token         |
| `/auth/forgot-password`   | POST   | âŒ    | Send OTP for reset                   |
| `/auth/change-password`   | POST   | âœ…    | Change password                      |
| `/user/me`                | GET    | âœ…    | Get current user profile             |
| `/chatroom`               | POST   | âœ…    | Create a new chatroom                |
| `/chatroom`               | GET    | âœ…    | List all chatrooms (cached)          |
| `/chatroom/{id}`          | GET    | âœ…    | Get single chatroom                  |
| `/chatroom/{id}/message`  | POST   | âœ…    | Send a message and queue AI response |
| `/chatroom/{id}/messages` | GET    | âœ…    | Fetch chatroom messages              |
| `/subscribe/pro`          | POST   | âœ…    | Start Stripe checkout                |
| `/webhook/stripe`         | POST   | âŒ    | Stripe event handler                 |
| `/subscription/status`    | GET    | âœ…    | Get user plan status                 |
| `/chatroom/usage`         | GET    | âœ…    | Daily usage stats                    |

---

## ğŸ“¦ Installation & Local Setup

```bash
git clone <your-repo>
cd gemini-backend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### .env Example:

```env
DATABASE_URL=postgresql://user:pass@localhost/db
REDIS_URL=redis://localhost:6379
STRIPE_SECRET_KEY=sk_test_...
DOMAIN=http://localhost:8000
GROQ_API_KEY=your_groq_key
BASIC_DAILY_LIMIT=5
JWT_SECRET=your_jwt_secret
```

### Run App:

```bash
uvicorn app.main:app --reload
```

### Run Worker:

```bash
python redis_worker.py
```

---

## ğŸ“¬ Postman Collection

* Covers all endpoints
* Includes authentication & JWT tokens
* Organized by folders:

  * Auth
  * Chatroom
  * Messages
  * Subscriptions
  * Stripe Webhooks

---

## ğŸ§± Architecture

* FastAPI â†’ REST APIs
* Redis â†’ queue + cache
* PostgreSQL â†’ persistent storage
* Stripe â†’ webhook, checkout
* Worker â†’ async processing
* JWT â†’ secure auth layer

---

## âœ¨ Queue System Overview

```text
[POST /chatroom/{id}/message]
          â”‚
       Save User Msg
          â”‚
     push_task() â Redis Queue
                      â”‚
                redis_worker.py
                      â”‚
       Call Groq API â Save AI Msg
```

---

## ğŸ¤– Gemini API (Groq) Integration

* Compatible with OpenAI SDK
* Uses `llama3-70b-8192` model
* Responses are delayed by worker (non-blocking)
* Delivered via background saving

---

## âœ… Assumptions & Notes

* OTPs are mocked (no SMS gateway)
* User identity = mobile number
* Stripe runs in test mode only
* AI responses are not streamed
* Webhook routes are public by design (Stripe-only access)

---

## ğŸ§ª Testing Instructions (Postman)

1. `POST /auth/send-otp` â€“ get OTP
2. `POST /auth/verify-otp` â€“ get JWT token
3. Use `Bearer <token>` for all next requests
4. Create chatroom â†’ send message
5. Poll `/chatroom/{id}/messages` to view AI response
6. Subscribe using `/subscribe/pro`
7. Verify Pro tier via `/subscription/status`

---

## ğŸŒ Deployment

* Backend: [Render](https://gemini-backend-bjhb.onrender.com)
* Worker: Deployed on Render (background process)
* DB: Render PostgreSQL
* Redis: Render (Cloud Redis)

---

